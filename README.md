# LangGraph Agentic RAG

åŸºäº **LangGraph v1** å’Œ **PGVector** çš„æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼Œå®ç°å¼‚æ­¥ã€å¯æŒä¹…åŒ–çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰Agentã€‚

å½“å‰å®ç°çš„æ˜¯ä¸€ä¸ª **ç®€åŒ–ç‰ˆ Agentic RAG**ï¼šLLM è‡ªä¸»åˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢æ–‡æ¡£ï¼Œä½¿ç”¨å·¥å…·ä» PGVector æ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œå¹¶åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆï¼›åŒæ—¶é€šè¿‡ LangGraph çš„ **Postgres checkpointer** æ”¯æŒåŸºäº `thread_id` çš„çŸ­æœŸè®°å¿†ï¼ˆå¯¹è¯çº¿ç¨‹ï¼‰ã€‚

å‚è€ƒæ–‡æ¡£ï¼š
- [LangGraph Agentic RAG æ•™ç¨‹](https://docs.langchain.com/oss/python/langgraph/agentic-rag)
- [LangChain RAG æŒ‡å—](https://docs.langchain.com/oss/python/langchain/rag)
- [LangGraph æŒä¹…åŒ–ä¸è®°å¿†](https://docs.langchain.com/oss/python/langgraph/add-memory)

## åŠŸèƒ½ç‰¹æ€§

- ğŸ§  **æ™ºèƒ½å†³ç­–**ï¼šLLM é€šè¿‡å·¥å…·è°ƒç”¨å†³å®šæ˜¯å¦éœ€è¦æ£€ç´¢æ–‡æ¡£
- ğŸ” **è¯­ä¹‰æ£€ç´¢**ï¼šPGVector + OpenAI `text-embedding-3-large`
- ğŸ’¬ **DashScope Qwen**ï¼šä½¿ç”¨é˜¿é‡Œäº‘é€šä¹‰åƒé—®ä½œä¸ºæ¨ç†æ¨¡å‹ï¼ˆç» OpenAI å…¼å®¹æ¥å£ï¼‰
- ğŸ’¾ **çŸ­æœŸè®°å¿†**ï¼šåŸºäº `thread_id` çš„å¯¹è¯çº¿ç¨‹ï¼Œé€šè¿‡ Postgres checkpointer æŒä¹…åŒ–
- ğŸ§± **æ¨¡å—åŒ–ç»“æ„**ï¼š`agent`ï¼ˆå›¾ä¸çŠ¶æ€ï¼‰ã€`tools`ï¼ˆå·¥å…·ï¼‰ã€`utils`ï¼ˆé€šç”¨å‡½æ•°ï¼‰ã€`config`ï¼ˆé…ç½®ï¼‰ã€`db`ï¼ˆæŒä¹…åŒ–ï¼‰

## æ¶æ„è®¾è®¡ï¼ˆå½“å‰ç®€åŒ–ç‰ˆï¼‰

```text
ç”¨æˆ·é—®é¢˜
  â†“
query_or_respond (LLM å†³ç­–ï¼Œæ˜¯å¦è°ƒç”¨æ£€ç´¢å·¥å…·)
  â”œâ”€â†’ æ—  tool_calls â†’ ç›´æ¥å›ç­” â†’ END
  â””â”€â†’ æœ‰ tool_calls â†’ tools (retrieve_context)
       â†“
                       generate (åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ) â†’ END
```

åç»­å¯ä»¥æŒ‰ [å®˜æ–¹ Agentic RAG æ•™ç¨‹](https://docs.langchain.com/oss/python/langgraph/agentic-rag) æ‰©å±• `grade_documents` / `rewrite_question` ç­‰èŠ‚ç‚¹ã€‚

## é¡¹ç›®ç»“æ„ï¼ˆç®€åŒ–ï¼‰

```text
rag_demo/
â”œâ”€â”€ data/                      # PDF æ–‡æ¡£å­˜æ”¾ç›®å½•
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ init_vectorstore.py    # æ–‡æ¡£ç´¢å¼•è„šæœ¬
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ context.py         # Runtime ä¸Šä¸‹æ–‡ï¼ˆé¢„ç•™ï¼‰
â”‚   â”‚   â”œâ”€â”€ graph.py           # LangGraph å›¾å®šä¹‰ï¼ˆå¼‚æ­¥èŠ‚ç‚¹ + checkpointerï¼‰
â”‚   â”‚   â”œâ”€â”€ state.py           # çŠ¶æ€ç®¡ç†ï¼ˆMessagesState æ‰©å±•ï¼‰
â”‚   â”‚   â””â”€â”€ vectorstore.py     # PGVector å°è£…ï¼ˆç´¢å¼•/æ£€ç´¢ï¼‰
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ retrieval.py       # æ£€ç´¢å·¥å…·ï¼ˆç»™ LLM è°ƒç”¨ï¼‰
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ llm.py             # æ¨¡å‹åŠ è½½ï¼ˆDashScope Qwenï¼Œç» ChatOpenAIï¼‰
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py        # å…¨å±€é…ç½®ï¼ˆç¯å¢ƒå˜é‡é›†ä¸­ç®¡ç†ï¼‰
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ database.py        # PostgreSQL è¿æ¥æ± ï¼ˆpsycopg_poolï¼‰
â”‚   â”‚   â”œâ”€â”€ checkpointer.py    # LangGraph PostgresSaver å°è£…ï¼ˆçŸ­æœŸè®°å¿†ï¼‰
â”‚   â”‚   â””â”€â”€ memory_store.py    # LangGraph AsyncPostgresStore å°è£…ï¼ˆé•¿æœŸè®°å¿†ï¼Œé¢„ç•™ï¼‰
â”‚   â””â”€â”€ api/                   # é¢„ç•™ç»™ FastAPI / LangGraph Agent Server é›†æˆ
â”œâ”€â”€ .env.example               # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ pyproject.toml             # é¡¹ç›®ä¾èµ–é…ç½®
â””â”€â”€ README.md                  # é¡¹ç›®æ–‡æ¡£
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -e .
```

ä¸»è¦ä¾èµ–ï¼š
- `langgraph`ï¼šLangGraph æ¡†æ¶ï¼ˆv1ï¼‰
- `langgraph-checkpoint` / `langgraph-checkpoint-postgres`ï¼šPostgres checkpointer
- `langchain-openai`ï¼šOpenAI å…¼å®¹æ¥å£
- `langchain-postgres`ï¼šPostgreSQL å‘é‡å­˜å‚¨
- `langchain-community`ï¼šæ–‡æ¡£åŠ è½½å™¨ç­‰å·¥å…·
- `langchain-text-splitters`ï¼šæ–‡æ¡£åˆ†å—
- `pypdf`ï¼šPDF è§£æ
- `psycopg[binary]`ï¼šPostgreSQL é©±åŠ¨

### 2. é…ç½®ç¯å¢ƒå˜é‡

å¤åˆ¶ `.env.example` åˆ° `.env` å¹¶å¡«å†™å¿…è¦çš„é…ç½®ï¼š

```bash
cp .env.example .env
```

å…³é”®é…ç½®ï¼ˆä¸ `config/settings.py` å¯¹åº”ï¼‰ï¼š

```env
# Embeddings ä¸“ç”¨ Key
OPENAI_EMBEDDINGS_API_KEY=your-embeddings-key

# DashScopeï¼ˆQwenï¼‰æ¨¡å‹é…ç½®ï¼ˆç» OpenAI å…¼å®¹åè®®è°ƒç”¨ï¼‰
MODEL_NAME=qwen-plus-latest
DASHSCOPE_API_KEY=your-dashscope-key
DASHSCOPE_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# PostgreSQL è¿æ¥å­—ç¬¦ä¸²ï¼ˆéœ€å¯ç”¨ pgvectorï¼‰
POSTGRES_CONNECTION_STRING=postgresql://username:password@localhost:5432/dbname

# å¯é€‰ï¼šè‡ªå®šä¹‰é›†åˆåä¸åˆ†å—å‚æ•°
VECTOR_COLLECTION=pdf_documents
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
RETRIEVER_TOP_K=2
```

> `config/settings.py` ä¼šè‡ªåŠ¨å°† `POSTGRES_CONNECTION_STRING` è½¬æ¢ä¸º `postgresql+psycopg://` å½¢å¼ä¾› PGVector ä½¿ç”¨ã€‚

### 3. å‡†å¤‡ PostgreSQL ä¸ pgvector

ç¡®ä¿ PostgreSQL å·²å¯ç”¨ `pgvector` æ‰©å±•ï¼š

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

### 4. å‡†å¤‡ PDF æ–‡æ¡£

```bash
mkdir -p data
# å°†ä½ çš„ PDF æ–‡ä»¶å¤åˆ¶åˆ° data/ ç›®å½•
cp /path/to/your/documents/*.pdf data/
```

### 5. ç´¢å¼•æ–‡æ¡£åˆ°å‘é‡åº“

ä½¿ç”¨è„šæœ¬å°† PDF æ–‡æ¡£ç´¢å¼•åˆ° PGVectorï¼š

```bash
python -m scripts.init_vectorstore
```

å¯é€‰å‚æ•°ï¼š

- `--pdf-dir`ï¼šPDF æ–‡ä»¶ç›®å½•ï¼ˆé»˜è®¤ `./data`ï¼‰
- `--collection-name`ï¼šé›†åˆåç§°ï¼ˆé»˜è®¤è¯»å– `VECTOR_COLLECTION` ç¯å¢ƒå˜é‡ï¼‰
- `--chunk-size`ï¼šæ–‡æœ¬å—å¤§å°ï¼ˆé»˜è®¤ `CHUNK_SIZE`ï¼‰
- `--chunk-overlap`ï¼šå—é‡å å¤§å°ï¼ˆé»˜è®¤ `CHUNK_OVERLAP`ï¼‰

ç¤ºä¾‹ï¼š

```bash
python -m scripts.init_vectorstore \
    --pdf-dir ./data \
  --collection-name pdf_documents \
    --chunk-size 1500 \
    --chunk-overlap 300
```

### 6. è¿è¡Œå¼‚æ­¥ RAG Agentï¼ˆæœ¬åœ°è°ƒç”¨ï¼‰

`src/agent/graph.py` æš´éœ²äº†ä¸€ä¸ªå¼‚æ­¥å›¾å®ä¾‹ `graph`ï¼Œå¹¶é»˜è®¤ä½¿ç”¨ Postgres checkpointer æ”¯æŒåŸºäº `thread_id` çš„çŸ­æœŸè®°å¿†ï¼š

```python
from agent.graph import graph

config = {"configurable": {"thread_id": "user-123"}}

result = await graph.ainvoke(
    {"messages": [{"role": "user", "content": "è¿™ä»½æ–‡æ¡£é‡Œæåˆ°äº†å“ªäº›å…³é”®æŠ€æœ¯ï¼Ÿ"}]},
    config,
)

print(result["messages"][-1].content)
```

å¦‚æœéœ€è¦æµå¼è¾“å‡ºï¼š

```python
async for update in graph.astream(
    {"messages": [{"role": "user", "content": "å¸®æˆ‘æ€»ç»“ä¸€ä¸‹æ–‡æ¡£çš„ä¸»è¦å†…å®¹"}]},
    config,
    stream_mode="updates",
):
    # update é‡Œä¼šåŒ…å«å„èŠ‚ç‚¹çš„å¢é‡æ¶ˆæ¯
    ...
```

> åŒä¸€ä¸ª `thread_id` ä¼šå…±äº«å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œä¸åŒ `thread_id` ä¹‹é—´ç›¸äº’éš”ç¦»ã€‚

### 7. FastAPI æ¥å£

é¡¹ç›®å†…ç½®äº†ä¸€ä¸ª FastAPI æœåŠ¡ï¼Œå¯ç›´æ¥å¯¹æ¥å·¥ä½œæµï¼š

```bash
uvicorn api.app:app --reload
```

`POST /chat` è¯·æ±‚ç¤ºä¾‹ï¼š

```json
{
  "thread_id": "user-123",
  "user_id": "alice",
  "message": "å¸®æˆ‘æ€»ç»“æ–‡æ¡£çš„å…³é”®ç»“è®º"
}
```

å“åº”ï¼š

```json
{
  "thread_id": "user-123",
  "user_id": "alice",
  "answer": "..."
}
```

FastAPI åœ¨å¯åŠ¨æ—¶ä¼šï¼š

1. åˆå§‹åŒ– PostgreSQL è¿æ¥æ± å’Œ LangGraph Postgres checkpointerï¼›
2. æ„å»ºå¼‚æ­¥ `graph` å®ä¾‹å¹¶ç¼“å­˜åˆ° `app.state`ï¼›
3. æ¯æ¬¡è°ƒç”¨ `/chat` æ—¶ï¼Œé€šè¿‡ `graph.ainvoke(...)` ä¸ LangGraph workflow äº¤äº’ã€‚

å½“éƒ¨ç½²åˆ° LangGraph Agent Server / Cloud æ—¶ï¼Œå¯é€šè¿‡ `langgraph dev` æˆ– `langgraph up` ç›´æ¥åŠ è½½ `graph`ï¼ˆæ­¤æ—¶ checkpointer ç”±å¹³å°ç®¡ç†ï¼‰ã€‚

## åç»­æ‰©å±•æ–¹å‘

- **Agentic RAG å®Œæ•´æµç¨‹**ï¼šå¢åŠ  `grade_documents` / `rewrite_question` ç­‰èŠ‚ç‚¹ï¼ˆå‚è€ƒå®˜æ–¹æ•™ç¨‹ï¼‰
- **é•¿æœŸè®°å¿†ï¼ˆè·¨çº¿ç¨‹ Storeï¼‰**ï¼šåŸºäº `src/db/memory_store.py` æ³¨å…¥ `AsyncPostgresStore`ï¼Œåœ¨èŠ‚ç‚¹ä¸­é€šè¿‡ `store: BaseStore` + `config: RunnableConfig` åšç”¨æˆ·è®°å¿†çš„è¯»å†™ï¼ˆå‚è€ƒå®˜æ–¹ [Add Memory æ–‡æ¡£](https://docs.langchain.com/oss/python/langgraph/add-memory)ï¼‰
- **API å±‚**ï¼šåœ¨ `src/api/` ä¸­ä½¿ç”¨ FastAPI å°è£…å¯¹ `graph` çš„ `ainvoke/astream` è°ƒç”¨

## è®¸å¯è¯

MIT License

## å‚è€ƒèµ„æº

- [LangGraph æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [LangGraph Agentic RAG æ•™ç¨‹](https://docs.langchain.com/oss/python/langgraph/agentic-rag)
- [LangChain RAG æ•™ç¨‹](https://docs.langchain.com/oss/python/langchain/rag)
- [PGVector æ–‡æ¡£](https://github.com/pgvector/pgvector)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬å¯¹è¯

```
ç”¨æˆ·: æ–‡æ¡£ä¸­æåˆ°äº†ä»€ä¹ˆå…³é”®æŠ€æœ¯?
Agent: [è‡ªåŠ¨è°ƒç”¨ retrieve_documents å·¥å…·æ£€ç´¢ç›¸å…³å†…å®¹]
Agent: æ ¹æ®æ–‡æ¡£,ä¸»è¦æåˆ°äº†ä»¥ä¸‹æŠ€æœ¯...
```

### ä¸ªæ€§åŒ–è®°å¿†

```
ç”¨æˆ·: æˆ‘å¯¹æœºå™¨å­¦ä¹ å¾ˆæ„Ÿå…´è¶£
Agent: [è‡ªåŠ¨å­˜å‚¨ç”¨æˆ·åå¥½åˆ° memory store]
Agent: æ˜ç™½äº†,æˆ‘ä¼šè®°ä½æ‚¨å¯¹æœºå™¨å­¦ä¹ çš„å…´è¶£...
```

## é…ç½®è¯´æ˜

### LLM æ¨¡å‹é…ç½®

é»˜è®¤ä½¿ç”¨ Anthropic Claude,å¯ä»¥åœ¨ç¯å¢ƒå˜é‡æˆ–ä»£ç ä¸­ä¿®æ”¹:

- Anthropic: `anthropic/claude-sonnet-4-5-20250929`
- OpenAI: `openai/gpt-4o`
- å…¶ä»–æ”¯æŒçš„æ¨¡å‹...

### æ£€ç´¢å‚æ•°

åœ¨ `vectorstore.py` ä¸­è°ƒæ•´æ£€ç´¢æ•°é‡:

```python
search_kwargs = {"k": 4}  # è¿”å›çš„æ–‡æ¡£æ•°é‡
```

### åˆ†å—ç­–ç•¥

åœ¨ `vectorstore.py` ä¸­è°ƒæ•´æ–‡æ¡£åˆ†å—å‚æ•°:

```python
chunk_size = 1000       # æ¯ä¸ªå—çš„æœ€å¤§å­—ç¬¦æ•°
chunk_overlap = 200     # å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°
```

## è®¸å¯è¯

MIT License

## å‚è€ƒèµ„æº

- [LangGraph æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [LangChain RAG æ•™ç¨‹](https://python.langchain.com/docs/tutorials/rag/)
- [PGVector æ–‡æ¡£](https://github.com/pgvector/pgvector)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)

Assuming the bot saved some memories, create a _new_ thread using the `+` icon. Then chat with the bot again - if you've completed your setup correctly, the bot should now have access to the memories you've saved!

You can review the saved memories by clicking the "memory" button.

![Memories Explorer](./static/memories.png)

## How it works

This chat bot reads from your memory graph's `Store` to easily list extracted memories. If it calls a tool, LangGraph will route to the `store_memory` node to save the information to the store.

## How to evaluate

Memory management can be challenging to get right, especially if you add additional tools for the bot to choose between.
To tune the frequency and quality of memories your bot is saving, we recommend starting from an evaluation set, adding to it over time as you find and address common errors in your service.

We have provided a few example evaluation cases in [the test file here](./tests/integration_tests/test_graph.py). As you can see, the metrics themselves don't have to be terribly complicated, especially not at the outset.

We use [LangSmith's @unit decorator](https://docs.smith.langchain.com/how_to_guides/evaluation/unit_testing#write-a-test) to sync all the evaluations to LangSmith so you can better optimize your system and identify the root cause of any issues that may arise.

## How to customize

1. Customize memory content: we've defined a simple memory structure `content: str, context: str` for each memory, but you could structure them in other ways.
2. Provide additional tools: the bot will be more useful if you connect it to other functions.
3. Select a different model: We default to anthropic/claude-3-5-sonnet-20240620. You can select a compatible chat model using provider/model-name via configuration. Example: openai/gpt-4.
4. Customize the prompts: We provide a default prompt in the [prompts.py](src/memory_agent/prompts.py) file. You can easily update this via configuration.
